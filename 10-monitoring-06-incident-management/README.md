# Домашнее задание к занятию "10.06. Инцидент-менеджмент"

## Задание 

Составьте постмортем, на основе реального сбоя системы Github в 2018 году.

Информация о сбое доступна [в виде краткой выжимки на русском языке](https://habr.com/ru/post/427301/) , а
также [развёрнуто на английском языке](https://github.blog/2018-10-30-oct21-post-incident-analysis/).

**Answer**

<sub>_Статья из задания уже является postmortem_</sub>

__Название:__ сбой репликации MySQL сервисов

__Время начала:__ 21.10.2018 22:52 UTC

__Время завершения:__ 22.10.2018 23:03 UTC

__Пострадавшие сервисы и функции:__ 
  - notification services (webhooks)
  - issues
  - building github pages

__Регион:__ глобальная проблема

__Предшествующие события:__ запланированная замена неисправного сетевого модуля в датацентре.

__Краткое описание:__ замена неисправного сетевого модуля привела к потере связности между датацентрами, повлекшей за собой нарушение целостности данных в MySQL и проблемам в работе некоторых сервисов. Для выполнения работ по восстановлению были принудительно выключены сервисы notification, pushes и build pages.

__Восстановление:__ произведено восстановление данных MySQL из бэкапа, восстановлена репликация, восстановлена топология репликации, восстановлена работа выключенных сервисов.

__Таймлайн:__ 
- _2018 October 21 22:52 UTC:_ запланированная замена неисправного сетевого модуля привела к 43 секундной потере сетевой связности между двумя датацентрами, в которых находились члены MySQL кластеров. Кластера были настроены таким образом, что на запись работали основные ноды в датацентре US East Coast, а остальные ноды, в том числе расположенные в датацентре US West Coast, служили только для чтения. В результате потери связности между датацентрами произошел штатный фейловер: кластер выбрал нового лидера, была перестроена топология репликации, и запись данных стала осуществляться на ноды, расположенные в датацентре US West Coast. 
- _2018 October 21 22:54 UTC:_ появились многочисленные алерты о сбоях в работе. Инженеры первой линии поддержки выявили, что это было вызвано изменившейся топологией кластеров MySQL.
- _2018 October 21 23:07 UTC:_ кластер был переведен в ручной режим управления топологией. Это повысило приоритет инцидента, поэтому к работам подключились владельцы сервиса (DBA).
- _2018 October 21 23:13 UTC:_ на этом этапе было обнаружено, что ни один из датацентров не содержит полной реплики данных: новые данные пишутся в датацентр US West Coast уже более получаса, но при этом в датацентре US East Coast содержится некоторое количество записей, которые не успели отреплицироваться из-за нарушения сетевой связности. Дополнительной проблемой являлось то, что из-за изменения топологии базы данных и приложения, их использующие, находятся в разных датацентрах, поэтому возникла дополнительная задержка записи, приводящая к многочисленным ошибкам у пользователей.
- _2018 October 21 23:19 UTC:_ чтобы обеспечить целостность данных, было принято решение об отключении некоторых служб: pages jobs, webhooks, pushes.
- _2018 October 22 00:05 UTC:_ разработан пошаговый план восстановления данных из бэкапа, восстановления топологии кластера и запуска остановленных сервисов.
- _2018 October 22 00:41 UTC:_ начато восстановление из бэкапа. Поскольку данные бэкапа хранились в отдельной локации, то их передача, проверка целостности и распаковка заняли значительное количество времени.
- _2018 October 22 06:51 UTC:_ включили репликацию свежих данных после завершения восстановления из бэкапа. Значительный объем данных репликации между датацентрами увеличил время отклика на пользовательские запросы. Несогласованность реплик приводила к тому, что пользователи могли получать устаревшие данные.
- _2018 October 22 11:12 UTC:_ частично восстановлена правильная топология кластеров, что в общем повысило скорость пользовательских запросов, но так как репликация отдельных кластеров еще не была завершена, то пользователи всё еще получали некорректные ответы. Дополнительной проблемой служило то, что с наступлением дня повысилась пользовательская нагрузка, снизившая скорость восстановления данных.
- _2018 October 22 13:15 UTC:_ пользовательская нагрузка достигла пиковых значений. В совокупности с задачами восстановления данных сервера перестали справляться с нагрузкой, поэтому были в кластера были добавлены новые ноды.
- _2018 October 22 16:24 UTC:_ полностью восстановлена топология кластеров, начата работа по включению notification сервисов, отключенных ранее.
- _2018 October 22 16:45 UTC:_ для восстановления работы notification сервисов была проведена дополнительная работа по балансировке дополнительной нагрузки, а также обновлены значения TTL для тех хуков, у которых истекло время жизни.
- _2018 October 22 23:03 UTC:_ работы по восстановлению завершены.

__Последующие действия:__ во время инцидента были собраны бинарные логи с кластеров, уточнено количество неотреплицировавшихся записей и проведена дополнительная работа по их анализу и восстановлению.

__Извлеченные уроки:__ 
- добавлены новые настройки, предотвращающие фейловер write-нод в другой регион в целях избежания задержек записи;
- улучшена система коммуникации с пользователями в случае инцидентов;
- ускорена разработка архитектуры, способной выдерживать падение целого датацентра;
- улучшена процедура документирования, позволяющая донести цель и смысл тех или иных технических решений;
- внедрены процедуры анализа возможных сценариев сбоя.