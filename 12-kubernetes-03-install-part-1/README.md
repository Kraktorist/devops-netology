# Домашнее задание к занятию "12.3 Развертывание кластера на собственных серверах, лекция 1"
Поработав с персональным кластером, можно заняться проектами. Вам пришла задача подготовить кластер под новый проект.

## Задание 1: Описать требования к кластеру
Сначала проекту необходимо определить требуемые ресурсы. Известно, что проекту нужны база данных, система кеширования, а само приложение состоит из бекенда и фронтенда. Опишите, какие ресурсы нужны, если известно:

* База данных должна быть отказоустойчивой. Потребляет 4 ГБ ОЗУ в работе, 1 ядро. 3 копии.
* Кэш должен быть отказоустойчивый. Потребляет 4 ГБ ОЗУ в работе, 1 ядро. 3 копии.
* Фронтенд обрабатывает внешние запросы быстро, отдавая статику. Потребляет не более 50 МБ ОЗУ на каждый экземпляр, 0.2 ядра. 5 копий.
* Бекенд потребляет 600 МБ ОЗУ и по 1 ядру на копию. 10 копий.


План расчета
1. Сначала сделайте расчет всех необходимых ресурсов.
2. Затем прикиньте количество рабочих нод, которые справятся с такой нагрузкой.
3. Добавьте к полученным цифрам запас, который учитывает выход из строя как минимум одной ноды.
4. Добавьте служебные ресурсы к нодам. Помните, что для разных типов нод требования к ресурсам разные.
5. Рассчитайте итоговые цифры.
6. В результате должно быть указано количество нод и их параметры.

**Answer**
  
1. __Общая полезная нагрузка.__ Примем, что указанные в требованиях ресурсы являются максимальными.
  
    | Тип      | Количество под | Память на под (Mb) |  CPU на под | Итого памяти | Итого CPU |
    | :---:    |  :---:         |       :---:        |    :---:    |     :---:    |   :--:    |
    | БД       |        3       |       4096         |      1      |     12288    |     3     |
    | Кэш      |        3       |       4096         |      1      |     12288    |     3     |
    | Фронтенд |        5       |       50           |      0.2    |     250      |     1     |
    | Бэкенд   |        10      |       600          |      1      |     6000     |     10    |
    | __Итого__|      __21__    |        -           |      -      |   __30826__  |   __17__  |


2. __Выбор размера и количества воркеров.__ Поскольку требуется обеспечить отказоустойчивость для сервисов БД и кэша, то с этой точки зрения отдельных нод-воркеров должно быть не меньше трех (плюс один резервный по отдельному требованию).  
Количество воркеров сверху ограничено ресурсами, которых должно быть достаточно для размещения самого большого пода с лимитами `cpu: 1` и `memory: 4Gi`. Просчитаем возможные варианты:
  
    | Количество воркеров | CPU | Memory |
    | :---:          | :---: | :---: | 
    | 3 | 6 | 11 |
    | __4__	| __5__	| __8__  |
    | 5	| 4	| 7  |
    | 6	| 3	| 6  |
    | 7	| 3	| 5  |
    | 8	| 3	| 4  |  
    
    Из представленных вариантов имеет смысл выбрать 4 воркера и добавить к ним еще один резервный. В этом случае мы сможем через механизм `nodeAffinity` управлять размещением подов по воркерам: например, три ноды выделить под бд и кэш, а на остальных нодах разместить прочую нагрузку. Таким образом можно уменьшить взаимное влияние подов с разной нагрузкой друг на друга.
  Выбор большего количества воркеров может привести к увеличению объема работ по их обслуживанию, а также к падению коэффициента полезного использования ресурсов.

3. __Служебная нагрузка.__ Считаем, что на каждом воркере нам понадобится `cpu: 1` и `memory: 1024` для запуска системных под (CNI, coredns, kube-proxy, ingress-controller итп).
Для отказоустойчивости кластера будем использовать [stacked etcd topology cluster](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/ha-topology/#stacked-etcd-topology) с тремя мастер-нодами `cpu: 2` и `memory: 2Gi`

4. __Общая конфигурация__

    | Тип ноды | Количество | CPU | Memory |
    | :---:          | :---: | :---: | :---: | 
    | master | 3 | 2 | 2 |
    | worker | 5 | 6 | 9 |