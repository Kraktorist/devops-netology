# Домашнее задание к занятию "11.03 Микросервисы: подходы"

Вы работаете в крупной компанию, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps специалисту необходимо выдвинуть предложение по организации инфраструктуры, для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- Облачная система;
- Система контроля версий Git;
- Репозиторий на каждый сервис;
- Запуск сборки по событию из системы контроля версий;
- Запуск сборки по кнопке с указанием параметров;
- Возможность привязать настройки к каждой сборке;
- Возможность создания шаблонов для различных конфигураций сборок;
- Возможность безопасного хранения секретных данных: пароли, ключи доступа;
- Несколько конфигураций для сборки из одного репозитория;
- Кастомные шаги при сборке;
- Собственные докер образы для сборки проектов;
- Возможность развернуть агентов сборки на собственных серверах;
- Возможность параллельного запуска нескольких сборок;
- Возможность параллельного запуска тестов;

Обоснуйте свой выбор.

**Answer**

Популярные публичные облачные платформы содержат все необходимые компоненты для построения CI/CD. Например, `AWS Codepipeline`, `Azure DevOps`, `Google Cloud Build` и `Alibaba Cloud DevOps Flow` в одноименных облаках могут быть скомбинированы с сервисами container registry и VCS.
Из отдельных продуктов, предлагающих CI/CD as a Service, можно выделить `circleci`, `gitlab`, `github/github actions`, `teamcity`, `bitbucket`.
Наиболее подходящим решениями будут `gitlab SaaS` или `github`, реализующие все заявленные функции.
В `circleci`, `teamcity`, `bitbucket` придется воспользоваться сторонними ресурсами хранения контейнеров для сборки. В качестве таковых могут быть использованы, например, hub.docker.com или quay.io.
В зависимости от требований к хранению секретов может потребоваться дополнительный сервис, например `Hashicorp Vault`.

---

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- Сбор логов в центральное хранилище со всех хостов обслуживающих систему;
- Минимальные требования к приложениям, сбор логов из stdout;
- Гарантированная доставка логов до центрального хранилища;
- Обеспечение поиска и фильтрации по записям логов;
- Обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- Возможность дать ссылку на сохраненный поиск по записям логов;

Обоснуйте свой выбор.

**Answer**

Есть несколько различных вариантов, подходящих для разных масштабов:
1. `Elasticsearch` для хранения, `Graylog` в качестве коллектора и UI, и `Fluentd` в качестве сборщика логов.
2. `Loki` для сбора и хранения, `Grafana` для поиска и отображения, и `Promtail` в качестве агента-сборщика.
3. `Elasticsearch` для хранения, `Logstash` или `Logstash`+`Kafka` в качестве коллектора, `Beats`/`Fluentd` в качестве сборщиков, `Kibana` в качестве UI для поиска и управления.

Вариант 3 является наиболее тяжелым в управлении, но в то же время наиболее универсальным решением, подходящим для больших нагрузок.

---

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- Сбор метрик со всех хостов, обслуживающих систему;
- Сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- Сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- Сбор метрик, специфичных для каждого сервиса;
- Пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- Пользовательский интерфейс с возможность настраивать различные панели для отслеживания состояния системы;

Обоснуйте свой выбор.

**Answer**

Такое решение возможно построить на базе `prometheus`. Контейнерная платформа `kubernetes` поддерживает service discovery и выдачу метрик в формате `prometheus`, а для сбора метрик с хостов и сервисов, нативно не поддерживающих работу с `prometheus`, существуют экспортеры. В частности `node_exporter` для сбора метрик с хостов.
В качестве пользовательского интерфейса используется `grafana`, а в качестве долговременного хранилища можно использовать `victoria metrics`.

---

## Задача 4: Логи * (необязательная)

<details>

__<summary>Условие задачи</summary>__

Продолжить работу по задаче API Gateway: сервисы используемые в задаче пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов обеспечивающих работу API.

### Результат выполнения: 

docker compose файл запустив который можно перейти по адресу http://localhost:8081 по которому доступна Kibana.
Логин в Kibana должен быть admin пароль qwerty123456

</details>

## Задача 5: Мониторинг * (необязательная)


<details>

__<summary>Условие задачи</summary>__

Продолжить работу по задаче API Gateway: сервисы используемые в задаче предоставляют набор метрик в формате prometheus:

- Сервис security по адресу /metrics
- Сервис uploader по адресу /metrics
- Сервис storage (minio) по адресу /minio/v2/metrics/cluster

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов обеспечивающих работу API.
Построить в Graphana dashboard показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл запустив который можно перейти по адресу http://localhost:8081 по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin пароль qwerty123456

</details>

___  

**Answers**

[docker-compose](assets/docker-compose.yaml)
```
docker-compose --env-file=.env up -d
```

[kibana](http://localhost:8081)

[grafana](http://localhost:8082)